<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Optimization on Not Much of a Blog</title>
    <link>https://tkngch.github.io/tags/optimization/</link>
    <description>Recent content in Optimization on Not Much of a Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>&amp;copy; 2016 Takao Noguchi. Creative Commons Attribution 4.0 International License.</copyright>
    <lastBuildDate>Sun, 19 Feb 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://tkngch.github.io/tags/optimization/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Gradient Descent by Gradient Descent</title>
      <link>https://tkngch.github.io/post/2017-02-19_gradient-descent-by-gradient-descent/</link>
      <pubDate>Sun, 19 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tkngch.github.io/post/2017-02-19_gradient-descent-by-gradient-descent/</guid>
      <description>&lt;p&gt;In this blog post, I review the 2016 NIPS paper &amp;ldquo;learning to learn by gradient
descent by gradient descent&amp;rdquo; (I abbreviate as LLGG) by Andrychowicz et al.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Long Short-Term Memory Network and Back-Propagation through Time</title>
      <link>https://tkngch.github.io/post/2017-01-29_long-short-term-memory-network/</link>
      <pubDate>Sun, 29 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tkngch.github.io/post/2017-01-29_long-short-term-memory-network/</guid>
      <description>&lt;p&gt;Recurrent neural networks (RNNs) are neural networks to model sequential data.
RNNs are often used in speech recognition and natural language processing. In
this blog post, I discuss one of the most popular RNNs, a long short-term
memory (LSTM) network. Then I briefly address a training procedure for a LSTM.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hidden Markov Model</title>
      <link>https://tkngch.github.io/post/2017-01-15_hidden-markov-model/</link>
      <pubDate>Sun, 15 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tkngch.github.io/post/2017-01-15_hidden-markov-model/</guid>
      <description>&lt;p&gt;Deep learning is quite popular in sequence modelling, but this blog post
discusses a more traditional model, a hidden Markov model.&lt;/p&gt;

&lt;p&gt;(Updated on 18 March 2017)&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>